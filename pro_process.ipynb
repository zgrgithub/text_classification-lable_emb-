{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pickle\n",
    "\n",
    "loadpath = './test.csv'\n",
    "x = []\n",
    "for line in open(loadpath,\"rb\"):\n",
    "    x.append(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_str(string):\n",
    "    \"\"\"\n",
    "    Tokenization/string cleaning for all datasets except for SST.\n",
    "    Every dataset is lower cased except for TREC\n",
    "    \"\"\"\n",
    "    string = re.sub(r\"\\'s\", \" is\", string)\n",
    "    string = re.sub(r\"[^A-Za-z0-9(),\\.!?]\", \" \", string)\n",
    "    #string = re.sub(r\"\\'s\", \" \\'s\", string)\n",
    "    string = re.sub(r\"e\\.g\\.,\", \" \", string)\n",
    "    string = re.sub(r\"a\\.k\\.a\\.\", \" \", string)\n",
    "    string = re.sub(r\"i\\.e\\.,\", \" \", string)\n",
    "    string = re.sub(r\"i\\.e\\.\", \" \", string)\n",
    "    #string = re.sub(r\"\\'ve\", \" \\'ve\", string)\n",
    "    #string = re.sub(r\"\\'\", \"\", string)\n",
    "    #string = re.sub(r\"\\'re\", \" \\'re\", string)\n",
    "    #string = re.sub(r\"\\'d\", \" \\'d\", string)\n",
    "    #string = re.sub(r\"\\'ll\", \" \\'ll\", string)\n",
    "    string = re.sub(r\",\", \" , \", string)\n",
    "    string = re.sub(r\"br\", \"\", string)\n",
    "    string = re.sub(r\"!\", \" ! \", string)\n",
    "    string = re.sub(r\"\\(\", \" ( \", string)\n",
    "    string = re.sub(r\"\\)\", \" ) \", string)\n",
    "    string = re.sub(r\"\\?\", \" ? \", string)\n",
    "    string = re.sub(r\"\\.\", \" . \", string)\n",
    "    string = re.sub(r\"\\s{2,}\", \" \", string)\n",
    "    string = re.sub(r\"u\\.s\\.\", \" us \", string)\n",
    "    return string.strip().lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_number(s):\n",
    "    try:\n",
    "        float(s)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "lab = []      #测试集标签\n",
    "sent = []     #测试集句子\n",
    "vocab = {}    #词典"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(60000):\n",
    "    line = str(x[i]).rstrip(\"\\\\n\\''\")\n",
    "    index = [i for i in range(len(line)) if line[i] == \",\"]\n",
    "    sent_start_index = index[2]\n",
    "    temp = clean_str(line[sent_start_index+1:]).split()\n",
    "    temp = [ j if not is_number(j) else '0' for j in temp]\n",
    "    if len(temp) > 300:\n",
    "        lab.append(clean_str(line.split(\",\")[0]).replace(\"b \",\"\"))\n",
    "        temp = temp[:300]\n",
    "        sent.append(temp)\n",
    "    elif len(temp) <= 5: # remove too short question\n",
    "        continue\n",
    "    else:\n",
    "        lab.append(clean_str(line.split(\",\")[0]).replace(\"b \",\"\"))\n",
    "        sent.append(temp)\n",
    "    \n",
    "    for word in temp:\n",
    "        if word in vocab:\n",
    "            vocab[word] += 1\n",
    "        else:\n",
    "            vocab[word] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "loadpath = './train.csv'\n",
    "\n",
    "x = []\n",
    "for line in open(loadpath,\"rb\"):\n",
    "    x.append(line)\n",
    "\n",
    "train_lab = []      #测试集标签\n",
    "train_sent = []     #测试集句子\n",
    "\n",
    "for i in range(len(x)):\n",
    "    line = str(x[i]).rstrip(\"\\\\n\\''\")\n",
    "    index = [i for i in range(len(line)) if line[i] == \",\"]\n",
    "    sent_start_index = index[2]\n",
    "    temp = clean_str(line[sent_start_index+1:]).split()\n",
    "    temp = [ j if not is_number(j) else '0' for j in temp]\n",
    "    if len(temp) > 300:\n",
    "        train_lab.append(clean_str(line.split(\",\")[0]).replace(\"b \",\"\"))\n",
    "        temp = temp[:300]\n",
    "        train_sent.append(temp)\n",
    "    elif len(temp) <= 5: # remove too short question\n",
    "        continue\n",
    "    else:\n",
    "        train_lab.append(clean_str(line.split(\",\")[0]).replace(\"b \",\"\"))\n",
    "        train_sent.append(temp)\n",
    "    \n",
    "    for word in temp:\n",
    "        if word in vocab:\n",
    "            vocab[word] += 1\n",
    "        else:\n",
    "            vocab[word] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ixtoword = {}\n",
    "# period at the end of the sentence. make first dimension be end token\n",
    "ixtoword[0] = 'END'\n",
    "ixtoword[1] = 'UNK'\n",
    "wordtoix = {}\n",
    "wordtoix['END'] = 0\n",
    "wordtoix['UNK'] = 1\n",
    "ix = 2\n",
    "for w in vocab:\n",
    "    wordtoix[w] = ix\n",
    "    ixtoword[ix] = w\n",
    "    ix += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_word_to_ix(data):\n",
    "    result = []\n",
    "    for sent in data:\n",
    "        temp = []\n",
    "        for w in sent:\n",
    "            if w in wordtoix:\n",
    "                temp.append(wordtoix[w])\n",
    "            else:\n",
    "                temp.append(1)\n",
    "        temp.append(0)\n",
    "        result.append(temp)\n",
    "    return result\n",
    "\n",
    "train_x = train_sent[:1100000]\n",
    "train_y = train_lab[:1100000]\n",
    "val_x = train_sent[1100000:]\n",
    "val_y = train_lab[1100000:]\n",
    "test_x = sent\n",
    "test_y = lab\n",
    "\n",
    "\n",
    "\n",
    "train_x = convert_word_to_ix(train_x)\n",
    "val_x = convert_word_to_ix(val_x)\n",
    "test_x = convert_word_to_ix(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump([train_x, val_x, test_x, train_y, val_y, test_y, wordtoix, ixtoword], open(\"yahoo4char.p\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'5'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
